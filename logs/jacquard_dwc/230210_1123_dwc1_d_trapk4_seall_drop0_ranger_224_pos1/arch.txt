----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 224, 224]             288
       BatchNorm2d-2         [-1, 32, 224, 224]              64
         Hardswish-3         [-1, 32, 224, 224]               0
            Conv2d-4         [-1, 32, 224, 224]             288
       BatchNorm2d-5         [-1, 32, 224, 224]              64
         Hardswish-6         [-1, 32, 224, 224]               0
       ConvBNLayer-7         [-1, 32, 224, 224]               0
 AdaptiveAvgPool2d-8             [-1, 32, 1, 1]               0
            Conv2d-9              [-1, 8, 1, 1]             264
             ReLU-10              [-1, 8, 1, 1]               0
           Conv2d-11             [-1, 32, 1, 1]             288
      Hardsigmoid-12             [-1, 32, 1, 1]               0
         SEModule-13         [-1, 32, 224, 224]               0
           Conv2d-14         [-1, 32, 224, 224]           1,024
      BatchNorm2d-15         [-1, 32, 224, 224]              64
        Hardswish-16         [-1, 32, 224, 224]               0
      ConvBNLayer-17         [-1, 32, 224, 224]               0
DepthwiseSeparable-18         [-1, 32, 224, 224]               0
           Conv2d-19         [-1, 32, 112, 112]             288
      BatchNorm2d-20         [-1, 32, 112, 112]              64
        Hardswish-21         [-1, 32, 112, 112]               0
      ConvBNLayer-22         [-1, 32, 112, 112]               0
AdaptiveAvgPool2d-23             [-1, 32, 1, 1]               0
           Conv2d-24              [-1, 8, 1, 1]             264
             ReLU-25              [-1, 8, 1, 1]               0
           Conv2d-26             [-1, 32, 1, 1]             288
      Hardsigmoid-27             [-1, 32, 1, 1]               0
         SEModule-28         [-1, 32, 112, 112]               0
           Conv2d-29         [-1, 64, 112, 112]           2,048
      BatchNorm2d-30         [-1, 64, 112, 112]             128
        Hardswish-31         [-1, 64, 112, 112]               0
      ConvBNLayer-32         [-1, 64, 112, 112]               0
DepthwiseSeparable-33         [-1, 64, 112, 112]               0
           Conv2d-34         [-1, 64, 112, 112]             576
      BatchNorm2d-35         [-1, 64, 112, 112]             128
        Hardswish-36         [-1, 64, 112, 112]               0
      ConvBNLayer-37         [-1, 64, 112, 112]               0
AdaptiveAvgPool2d-38             [-1, 64, 1, 1]               0
           Conv2d-39             [-1, 16, 1, 1]           1,040
             ReLU-40             [-1, 16, 1, 1]               0
           Conv2d-41             [-1, 64, 1, 1]           1,088
      Hardsigmoid-42             [-1, 64, 1, 1]               0
         SEModule-43         [-1, 64, 112, 112]               0
           Conv2d-44         [-1, 64, 112, 112]           4,096
      BatchNorm2d-45         [-1, 64, 112, 112]             128
        Hardswish-46         [-1, 64, 112, 112]               0
      ConvBNLayer-47         [-1, 64, 112, 112]               0
DepthwiseSeparable-48         [-1, 64, 112, 112]               0
           Conv2d-49           [-1, 64, 56, 56]             576
      BatchNorm2d-50           [-1, 64, 56, 56]             128
        Hardswish-51           [-1, 64, 56, 56]               0
      ConvBNLayer-52           [-1, 64, 56, 56]               0
AdaptiveAvgPool2d-53             [-1, 64, 1, 1]               0
           Conv2d-54             [-1, 16, 1, 1]           1,040
             ReLU-55             [-1, 16, 1, 1]               0
           Conv2d-56             [-1, 64, 1, 1]           1,088
      Hardsigmoid-57             [-1, 64, 1, 1]               0
         SEModule-58           [-1, 64, 56, 56]               0
           Conv2d-59          [-1, 128, 56, 56]           8,192
      BatchNorm2d-60          [-1, 128, 56, 56]             256
        Hardswish-61          [-1, 128, 56, 56]               0
      ConvBNLayer-62          [-1, 128, 56, 56]               0
DepthwiseSeparable-63          [-1, 128, 56, 56]               0
           Conv2d-64          [-1, 128, 56, 56]           1,152
      BatchNorm2d-65          [-1, 128, 56, 56]             256
        Hardswish-66          [-1, 128, 56, 56]               0
      ConvBNLayer-67          [-1, 128, 56, 56]               0
AdaptiveAvgPool2d-68            [-1, 128, 1, 1]               0
           Conv2d-69             [-1, 32, 1, 1]           4,128
             ReLU-70             [-1, 32, 1, 1]               0
           Conv2d-71            [-1, 128, 1, 1]           4,224
      Hardsigmoid-72            [-1, 128, 1, 1]               0
         SEModule-73          [-1, 128, 56, 56]               0
           Conv2d-74          [-1, 128, 56, 56]          16,384
      BatchNorm2d-75          [-1, 128, 56, 56]             256
        Hardswish-76          [-1, 128, 56, 56]               0
      ConvBNLayer-77          [-1, 128, 56, 56]               0
DepthwiseSeparable-78          [-1, 128, 56, 56]               0
           Conv2d-79          [-1, 128, 28, 28]           1,152
      BatchNorm2d-80          [-1, 128, 28, 28]             256
        Hardswish-81          [-1, 128, 28, 28]               0
      ConvBNLayer-82          [-1, 128, 28, 28]               0
AdaptiveAvgPool2d-83            [-1, 128, 1, 1]               0
           Conv2d-84             [-1, 32, 1, 1]           4,128
             ReLU-85             [-1, 32, 1, 1]               0
           Conv2d-86            [-1, 128, 1, 1]           4,224
      Hardsigmoid-87            [-1, 128, 1, 1]               0
         SEModule-88          [-1, 128, 28, 28]               0
           Conv2d-89          [-1, 256, 28, 28]          32,768
      BatchNorm2d-90          [-1, 256, 28, 28]             512
        Hardswish-91          [-1, 256, 28, 28]               0
      ConvBNLayer-92          [-1, 256, 28, 28]               0
DepthwiseSeparable-93          [-1, 256, 28, 28]               0
           Conv2d-94          [-1, 256, 28, 28]           6,400
      BatchNorm2d-95          [-1, 256, 28, 28]             512
        Hardswish-96          [-1, 256, 28, 28]               0
      ConvBNLayer-97          [-1, 256, 28, 28]               0
AdaptiveAvgPool2d-98            [-1, 256, 1, 1]               0
           Conv2d-99             [-1, 64, 1, 1]          16,448
            ReLU-100             [-1, 64, 1, 1]               0
          Conv2d-101            [-1, 256, 1, 1]          16,640
     Hardsigmoid-102            [-1, 256, 1, 1]               0
        SEModule-103          [-1, 256, 28, 28]               0
          Conv2d-104          [-1, 256, 28, 28]          65,536
     BatchNorm2d-105          [-1, 256, 28, 28]             512
       Hardswish-106          [-1, 256, 28, 28]               0
     ConvBNLayer-107          [-1, 256, 28, 28]               0
DepthwiseSeparable-108          [-1, 256, 28, 28]               0
          Conv2d-109          [-1, 256, 28, 28]           6,400
     BatchNorm2d-110          [-1, 256, 28, 28]             512
       Hardswish-111          [-1, 256, 28, 28]               0
     ConvBNLayer-112          [-1, 256, 28, 28]               0
AdaptiveAvgPool2d-113            [-1, 256, 1, 1]               0
          Conv2d-114             [-1, 64, 1, 1]          16,448
            ReLU-115             [-1, 64, 1, 1]               0
          Conv2d-116            [-1, 256, 1, 1]          16,640
     Hardsigmoid-117            [-1, 256, 1, 1]               0
        SEModule-118          [-1, 256, 28, 28]               0
          Conv2d-119          [-1, 256, 28, 28]          65,536
     BatchNorm2d-120          [-1, 256, 28, 28]             512
       Hardswish-121          [-1, 256, 28, 28]               0
     ConvBNLayer-122          [-1, 256, 28, 28]               0
DepthwiseSeparable-123          [-1, 256, 28, 28]               0
          Conv2d-124          [-1, 256, 28, 28]           6,400
     BatchNorm2d-125          [-1, 256, 28, 28]             512
       Hardswish-126          [-1, 256, 28, 28]               0
     ConvBNLayer-127          [-1, 256, 28, 28]               0
AdaptiveAvgPool2d-128            [-1, 256, 1, 1]               0
          Conv2d-129             [-1, 64, 1, 1]          16,448
            ReLU-130             [-1, 64, 1, 1]               0
          Conv2d-131            [-1, 256, 1, 1]          16,640
     Hardsigmoid-132            [-1, 256, 1, 1]               0
        SEModule-133          [-1, 256, 28, 28]               0
          Conv2d-134          [-1, 256, 28, 28]          65,536
     BatchNorm2d-135          [-1, 256, 28, 28]             512
       Hardswish-136          [-1, 256, 28, 28]               0
     ConvBNLayer-137          [-1, 256, 28, 28]               0
DepthwiseSeparable-138          [-1, 256, 28, 28]               0
          Conv2d-139          [-1, 256, 28, 28]           6,400
     BatchNorm2d-140          [-1, 256, 28, 28]             512
       Hardswish-141          [-1, 256, 28, 28]               0
     ConvBNLayer-142          [-1, 256, 28, 28]               0
AdaptiveAvgPool2d-143            [-1, 256, 1, 1]               0
          Conv2d-144             [-1, 64, 1, 1]          16,448
            ReLU-145             [-1, 64, 1, 1]               0
          Conv2d-146            [-1, 256, 1, 1]          16,640
     Hardsigmoid-147            [-1, 256, 1, 1]               0
        SEModule-148          [-1, 256, 28, 28]               0
          Conv2d-149          [-1, 256, 28, 28]          65,536
     BatchNorm2d-150          [-1, 256, 28, 28]             512
       Hardswish-151          [-1, 256, 28, 28]               0
     ConvBNLayer-152          [-1, 256, 28, 28]               0
DepthwiseSeparable-153          [-1, 256, 28, 28]               0
          Conv2d-154          [-1, 256, 28, 28]           6,400
     BatchNorm2d-155          [-1, 256, 28, 28]             512
       Hardswish-156          [-1, 256, 28, 28]               0
     ConvBNLayer-157          [-1, 256, 28, 28]               0
AdaptiveAvgPool2d-158            [-1, 256, 1, 1]               0
          Conv2d-159             [-1, 64, 1, 1]          16,448
            ReLU-160             [-1, 64, 1, 1]               0
          Conv2d-161            [-1, 256, 1, 1]          16,640
     Hardsigmoid-162            [-1, 256, 1, 1]               0
        SEModule-163          [-1, 256, 28, 28]               0
          Conv2d-164          [-1, 256, 28, 28]          65,536
     BatchNorm2d-165          [-1, 256, 28, 28]             512
       Hardswish-166          [-1, 256, 28, 28]               0
     ConvBNLayer-167          [-1, 256, 28, 28]               0
DepthwiseSeparable-168          [-1, 256, 28, 28]               0
          Conv2d-169           [-1, 64, 28, 28]          32,768
     BatchNorm2d-170           [-1, 64, 28, 28]             128
     ConvBNLayer-171           [-1, 64, 28, 28]               0
          Conv2d-172           [-1, 64, 28, 28]          32,768
     BatchNorm2d-173           [-1, 64, 28, 28]             128
     ConvBNLayer-174           [-1, 64, 28, 28]               0
          Conv2d-175           [-1, 64, 28, 28]           4,096
     BatchNorm2d-176           [-1, 64, 28, 28]             128
     ConvBNLayer-177           [-1, 64, 28, 28]               0
          Conv2d-178           [-1, 64, 28, 28]          36,864
     BatchNorm2d-179           [-1, 64, 28, 28]             128
     ConvBNLayer-180           [-1, 64, 28, 28]               0
DarknetBottleneck-181           [-1, 64, 28, 28]               0
          Conv2d-182          [-1, 128, 28, 28]          16,384
     BatchNorm2d-183          [-1, 128, 28, 28]             256
     ConvBNLayer-184          [-1, 128, 28, 28]               0
        CSPLayer-185          [-1, 128, 28, 28]               0
 ConvTranspose2d-186          [-1, 128, 56, 56]         262,272
              up-187          [-1, 128, 56, 56]               0
          Conv2d-188           [-1, 32, 56, 56]           8,192
     BatchNorm2d-189           [-1, 32, 56, 56]              64
     ConvBNLayer-190           [-1, 32, 56, 56]               0
          Conv2d-191           [-1, 32, 56, 56]           8,192
     BatchNorm2d-192           [-1, 32, 56, 56]              64
     ConvBNLayer-193           [-1, 32, 56, 56]               0
          Conv2d-194           [-1, 32, 56, 56]           1,024
     BatchNorm2d-195           [-1, 32, 56, 56]              64
     ConvBNLayer-196           [-1, 32, 56, 56]               0
          Conv2d-197           [-1, 32, 56, 56]           9,216
     BatchNorm2d-198           [-1, 32, 56, 56]              64
     ConvBNLayer-199           [-1, 32, 56, 56]               0
DarknetBottleneck-200           [-1, 32, 56, 56]               0
          Conv2d-201           [-1, 64, 56, 56]           4,096
     BatchNorm2d-202           [-1, 64, 56, 56]             128
     ConvBNLayer-203           [-1, 64, 56, 56]               0
        CSPLayer-204           [-1, 64, 56, 56]               0
 ConvTranspose2d-205         [-1, 64, 112, 112]          65,600
              up-206         [-1, 64, 112, 112]               0
          Conv2d-207         [-1, 16, 112, 112]           2,048
     BatchNorm2d-208         [-1, 16, 112, 112]              32
     ConvBNLayer-209         [-1, 16, 112, 112]               0
          Conv2d-210         [-1, 16, 112, 112]           2,048
     BatchNorm2d-211         [-1, 16, 112, 112]              32
     ConvBNLayer-212         [-1, 16, 112, 112]               0
          Conv2d-213         [-1, 16, 112, 112]             256
     BatchNorm2d-214         [-1, 16, 112, 112]              32
     ConvBNLayer-215         [-1, 16, 112, 112]               0
          Conv2d-216         [-1, 16, 112, 112]           2,304
     BatchNorm2d-217         [-1, 16, 112, 112]              32
     ConvBNLayer-218         [-1, 16, 112, 112]               0
DarknetBottleneck-219         [-1, 16, 112, 112]               0
          Conv2d-220         [-1, 32, 112, 112]           1,024
     BatchNorm2d-221         [-1, 32, 112, 112]              64
     ConvBNLayer-222         [-1, 32, 112, 112]               0
        CSPLayer-223         [-1, 32, 112, 112]               0
 ConvTranspose2d-224         [-1, 32, 224, 224]          16,416
              up-225         [-1, 32, 224, 224]               0
          Conv2d-226         [-1, 32, 224, 224]           1,024
     BatchNorm2d-227         [-1, 32, 224, 224]              64
            ReLU-228         [-1, 32, 224, 224]               0
          Conv2d-229          [-1, 1, 224, 224]              33
          Conv2d-230          [-1, 1, 224, 224]              33
          Conv2d-231          [-1, 1, 224, 224]              33
          Conv2d-232          [-1, 1, 224, 224]              33
================================================================
Total params: 1,131,572
Trainable params: 1,131,572
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 545.55
Params size (MB): 4.32
Estimated Total Size (MB): 550.06
----------------------------------------------------------------
