----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 1, 224, 224]               9
       BatchNorm2d-2          [-1, 1, 224, 224]               2
              ReLU-3          [-1, 1, 224, 224]               0
            Conv2d-4         [-1, 32, 224, 224]              32
       BatchNorm2d-5         [-1, 32, 224, 224]              64
         Hardswish-6         [-1, 32, 224, 224]               0
            Conv2d-7         [-1, 32, 224, 224]             288
       BatchNorm2d-8         [-1, 32, 224, 224]              64
         Hardswish-9         [-1, 32, 224, 224]               0
      ConvBNLayer-10         [-1, 32, 224, 224]               0
AdaptiveAvgPool2d-11             [-1, 32, 1, 1]               0
           Conv2d-12              [-1, 8, 1, 1]             264
             ReLU-13              [-1, 8, 1, 1]               0
           Conv2d-14             [-1, 32, 1, 1]             288
      Hardsigmoid-15             [-1, 32, 1, 1]               0
         SEModule-16         [-1, 32, 224, 224]               0
           Conv2d-17         [-1, 32, 224, 224]           1,024
      BatchNorm2d-18         [-1, 32, 224, 224]              64
        Hardswish-19         [-1, 32, 224, 224]               0
      ConvBNLayer-20         [-1, 32, 224, 224]               0
DepthwiseSeparable-21         [-1, 32, 224, 224]               0
           Conv2d-22         [-1, 32, 224, 224]             288
      BatchNorm2d-23         [-1, 32, 224, 224]              64
        Hardswish-24         [-1, 32, 224, 224]               0
      ConvBNLayer-25         [-1, 32, 224, 224]               0
AdaptiveAvgPool2d-26             [-1, 32, 1, 1]               0
           Conv2d-27              [-1, 8, 1, 1]             264
             ReLU-28              [-1, 8, 1, 1]               0
           Conv2d-29             [-1, 32, 1, 1]             288
      Hardsigmoid-30             [-1, 32, 1, 1]               0
         SEModule-31         [-1, 32, 224, 224]               0
           Conv2d-32         [-1, 32, 224, 224]           1,024
      BatchNorm2d-33         [-1, 32, 224, 224]              64
        Hardswish-34         [-1, 32, 224, 224]               0
      ConvBNLayer-35         [-1, 32, 224, 224]               0
DepthwiseSeparable-36         [-1, 32, 224, 224]               0
           Conv2d-37         [-1, 32, 112, 112]             288
      BatchNorm2d-38         [-1, 32, 112, 112]              64
        Hardswish-39         [-1, 32, 112, 112]               0
      ConvBNLayer-40         [-1, 32, 112, 112]               0
AdaptiveAvgPool2d-41             [-1, 32, 1, 1]               0
           Conv2d-42              [-1, 8, 1, 1]             264
             ReLU-43              [-1, 8, 1, 1]               0
           Conv2d-44             [-1, 32, 1, 1]             288
      Hardsigmoid-45             [-1, 32, 1, 1]               0
         SEModule-46         [-1, 32, 112, 112]               0
           Conv2d-47         [-1, 64, 112, 112]           2,048
      BatchNorm2d-48         [-1, 64, 112, 112]             128
        Hardswish-49         [-1, 64, 112, 112]               0
      ConvBNLayer-50         [-1, 64, 112, 112]               0
DepthwiseSeparable-51         [-1, 64, 112, 112]               0
             down-52         [-1, 64, 112, 112]               0
           Conv2d-53         [-1, 64, 112, 112]             576
      BatchNorm2d-54         [-1, 64, 112, 112]             128
        Hardswish-55         [-1, 64, 112, 112]               0
      ConvBNLayer-56         [-1, 64, 112, 112]               0
AdaptiveAvgPool2d-57             [-1, 64, 1, 1]               0
           Conv2d-58             [-1, 16, 1, 1]           1,040
             ReLU-59             [-1, 16, 1, 1]               0
           Conv2d-60             [-1, 64, 1, 1]           1,088
      Hardsigmoid-61             [-1, 64, 1, 1]               0
         SEModule-62         [-1, 64, 112, 112]               0
           Conv2d-63         [-1, 64, 112, 112]           4,096
      BatchNorm2d-64         [-1, 64, 112, 112]             128
        Hardswish-65         [-1, 64, 112, 112]               0
      ConvBNLayer-66         [-1, 64, 112, 112]               0
DepthwiseSeparable-67         [-1, 64, 112, 112]               0
           Conv2d-68           [-1, 64, 56, 56]             576
      BatchNorm2d-69           [-1, 64, 56, 56]             128
        Hardswish-70           [-1, 64, 56, 56]               0
      ConvBNLayer-71           [-1, 64, 56, 56]               0
AdaptiveAvgPool2d-72             [-1, 64, 1, 1]               0
           Conv2d-73             [-1, 16, 1, 1]           1,040
             ReLU-74             [-1, 16, 1, 1]               0
           Conv2d-75             [-1, 64, 1, 1]           1,088
      Hardsigmoid-76             [-1, 64, 1, 1]               0
         SEModule-77           [-1, 64, 56, 56]               0
           Conv2d-78          [-1, 128, 56, 56]           8,192
      BatchNorm2d-79          [-1, 128, 56, 56]             256
        Hardswish-80          [-1, 128, 56, 56]               0
      ConvBNLayer-81          [-1, 128, 56, 56]               0
DepthwiseSeparable-82          [-1, 128, 56, 56]               0
             down-83          [-1, 128, 56, 56]               0
           Conv2d-84          [-1, 128, 56, 56]           1,152
      BatchNorm2d-85          [-1, 128, 56, 56]             256
        Hardswish-86          [-1, 128, 56, 56]               0
      ConvBNLayer-87          [-1, 128, 56, 56]               0
AdaptiveAvgPool2d-88            [-1, 128, 1, 1]               0
           Conv2d-89             [-1, 32, 1, 1]           4,128
             ReLU-90             [-1, 32, 1, 1]               0
           Conv2d-91            [-1, 128, 1, 1]           4,224
      Hardsigmoid-92            [-1, 128, 1, 1]               0
         SEModule-93          [-1, 128, 56, 56]               0
           Conv2d-94          [-1, 128, 56, 56]          16,384
      BatchNorm2d-95          [-1, 128, 56, 56]             256
        Hardswish-96          [-1, 128, 56, 56]               0
      ConvBNLayer-97          [-1, 128, 56, 56]               0
DepthwiseSeparable-98          [-1, 128, 56, 56]               0
           Conv2d-99          [-1, 128, 56, 56]           1,152
     BatchNorm2d-100          [-1, 128, 56, 56]             256
       Hardswish-101          [-1, 128, 56, 56]               0
     ConvBNLayer-102          [-1, 128, 56, 56]               0
AdaptiveAvgPool2d-103            [-1, 128, 1, 1]               0
          Conv2d-104             [-1, 32, 1, 1]           4,128
            ReLU-105             [-1, 32, 1, 1]               0
          Conv2d-106            [-1, 128, 1, 1]           4,224
     Hardsigmoid-107            [-1, 128, 1, 1]               0
        SEModule-108          [-1, 128, 56, 56]               0
          Conv2d-109          [-1, 128, 56, 56]          16,384
     BatchNorm2d-110          [-1, 128, 56, 56]             256
       Hardswish-111          [-1, 128, 56, 56]               0
     ConvBNLayer-112          [-1, 128, 56, 56]               0
DepthwiseSeparable-113          [-1, 128, 56, 56]               0
          Conv2d-114          [-1, 128, 56, 56]           1,152
     BatchNorm2d-115          [-1, 128, 56, 56]             256
       Hardswish-116          [-1, 128, 56, 56]               0
     ConvBNLayer-117          [-1, 128, 56, 56]               0
AdaptiveAvgPool2d-118            [-1, 128, 1, 1]               0
          Conv2d-119             [-1, 32, 1, 1]           4,128
            ReLU-120             [-1, 32, 1, 1]               0
          Conv2d-121            [-1, 128, 1, 1]           4,224
     Hardsigmoid-122            [-1, 128, 1, 1]               0
        SEModule-123          [-1, 128, 56, 56]               0
          Conv2d-124          [-1, 128, 56, 56]          16,384
     BatchNorm2d-125          [-1, 128, 56, 56]             256
       Hardswish-126          [-1, 128, 56, 56]               0
     ConvBNLayer-127          [-1, 128, 56, 56]               0
DepthwiseSeparable-128          [-1, 128, 56, 56]               0
          Conv2d-129          [-1, 128, 56, 56]           1,152
     BatchNorm2d-130          [-1, 128, 56, 56]             256
       Hardswish-131          [-1, 128, 56, 56]               0
     ConvBNLayer-132          [-1, 128, 56, 56]               0
AdaptiveAvgPool2d-133            [-1, 128, 1, 1]               0
          Conv2d-134             [-1, 32, 1, 1]           4,128
            ReLU-135             [-1, 32, 1, 1]               0
          Conv2d-136            [-1, 128, 1, 1]           4,224
     Hardsigmoid-137            [-1, 128, 1, 1]               0
        SEModule-138          [-1, 128, 56, 56]               0
          Conv2d-139          [-1, 128, 56, 56]          16,384
     BatchNorm2d-140          [-1, 128, 56, 56]             256
       Hardswish-141          [-1, 128, 56, 56]               0
     ConvBNLayer-142          [-1, 128, 56, 56]               0
DepthwiseSeparable-143          [-1, 128, 56, 56]               0
          Conv2d-144          [-1, 128, 56, 56]           1,152
     BatchNorm2d-145          [-1, 128, 56, 56]             256
       Hardswish-146          [-1, 128, 56, 56]               0
     ConvBNLayer-147          [-1, 128, 56, 56]               0
AdaptiveAvgPool2d-148            [-1, 128, 1, 1]               0
          Conv2d-149             [-1, 32, 1, 1]           4,128
            ReLU-150             [-1, 32, 1, 1]               0
          Conv2d-151            [-1, 128, 1, 1]           4,224
     Hardsigmoid-152            [-1, 128, 1, 1]               0
        SEModule-153          [-1, 128, 56, 56]               0
          Conv2d-154          [-1, 128, 56, 56]          16,384
     BatchNorm2d-155          [-1, 128, 56, 56]             256
       Hardswish-156          [-1, 128, 56, 56]               0
     ConvBNLayer-157          [-1, 128, 56, 56]               0
DepthwiseSeparable-158          [-1, 128, 56, 56]               0
          Conv2d-159           [-1, 64, 56, 56]           8,192
     BatchNorm2d-160           [-1, 64, 56, 56]             128
     ConvBNLayer-161           [-1, 64, 56, 56]               0
          Conv2d-162           [-1, 64, 56, 56]           8,192
     BatchNorm2d-163           [-1, 64, 56, 56]             128
     ConvBNLayer-164           [-1, 64, 56, 56]               0
          Conv2d-165           [-1, 64, 56, 56]           4,096
     BatchNorm2d-166           [-1, 64, 56, 56]             128
     ConvBNLayer-167           [-1, 64, 56, 56]               0
          Conv2d-168           [-1, 64, 56, 56]          36,864
     BatchNorm2d-169           [-1, 64, 56, 56]             128
     ConvBNLayer-170           [-1, 64, 56, 56]               0
DarknetBottleneck-171           [-1, 64, 56, 56]               0
          Conv2d-172          [-1, 128, 56, 56]          16,384
     BatchNorm2d-173          [-1, 128, 56, 56]             256
     ConvBNLayer-174          [-1, 128, 56, 56]               0
        CSPLayer-175          [-1, 128, 56, 56]               0
          Conv2d-176           [-1, 32, 56, 56]           8,192
     BatchNorm2d-177           [-1, 32, 56, 56]              64
     ConvBNLayer-178           [-1, 32, 56, 56]               0
          Conv2d-179           [-1, 32, 56, 56]           8,192
     BatchNorm2d-180           [-1, 32, 56, 56]              64
     ConvBNLayer-181           [-1, 32, 56, 56]               0
          Conv2d-182           [-1, 32, 56, 56]           1,024
     BatchNorm2d-183           [-1, 32, 56, 56]              64
     ConvBNLayer-184           [-1, 32, 56, 56]               0
          Conv2d-185           [-1, 32, 56, 56]           9,216
     BatchNorm2d-186           [-1, 32, 56, 56]              64
     ConvBNLayer-187           [-1, 32, 56, 56]               0
DarknetBottleneck-188           [-1, 32, 56, 56]               0
          Conv2d-189           [-1, 64, 56, 56]           4,096
     BatchNorm2d-190           [-1, 64, 56, 56]             128
     ConvBNLayer-191           [-1, 64, 56, 56]               0
        CSPLayer-192           [-1, 64, 56, 56]               0
        Upsample-193         [-1, 64, 112, 112]               0
              up-194         [-1, 64, 112, 112]               0
          Conv2d-195         [-1, 16, 112, 112]           2,048
     BatchNorm2d-196         [-1, 16, 112, 112]              32
     ConvBNLayer-197         [-1, 16, 112, 112]               0
          Conv2d-198         [-1, 16, 112, 112]           2,048
     BatchNorm2d-199         [-1, 16, 112, 112]              32
     ConvBNLayer-200         [-1, 16, 112, 112]               0
          Conv2d-201         [-1, 16, 112, 112]             256
     BatchNorm2d-202         [-1, 16, 112, 112]              32
     ConvBNLayer-203         [-1, 16, 112, 112]               0
          Conv2d-204         [-1, 16, 112, 112]           2,304
     BatchNorm2d-205         [-1, 16, 112, 112]              32
     ConvBNLayer-206         [-1, 16, 112, 112]               0
DarknetBottleneck-207         [-1, 16, 112, 112]               0
          Conv2d-208         [-1, 32, 112, 112]           1,024
     BatchNorm2d-209         [-1, 32, 112, 112]              64
     ConvBNLayer-210         [-1, 32, 112, 112]               0
        CSPLayer-211         [-1, 32, 112, 112]               0
        Upsample-212         [-1, 32, 224, 224]               0
              up-213         [-1, 32, 224, 224]               0
          Conv2d-214         [-1, 32, 224, 224]           9,216
     BatchNorm2d-215         [-1, 32, 224, 224]              64
            ReLU-216         [-1, 32, 224, 224]               0
          Conv2d-217          [-1, 1, 224, 224]              33
          Conv2d-218          [-1, 1, 224, 224]              33
          Conv2d-219          [-1, 1, 224, 224]              33
          Conv2d-220          [-1, 1, 224, 224]              33
================================================================
Total params: 280,391
Trainable params: 280,391
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 730.81
Params size (MB): 1.07
Estimated Total Size (MB): 732.07
----------------------------------------------------------------
