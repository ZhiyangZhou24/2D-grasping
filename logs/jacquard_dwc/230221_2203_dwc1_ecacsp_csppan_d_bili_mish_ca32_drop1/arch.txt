----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 320, 320]             288
       BatchNorm2d-2         [-1, 32, 320, 320]              64
       ConvBNLayer-3         [-1, 32, 320, 320]               0
            Conv2d-4         [-1, 32, 320, 320]             288
       BatchNorm2d-5         [-1, 32, 320, 320]              64
         Hardswish-6         [-1, 32, 320, 320]               0
       ConvBNLayer-7         [-1, 32, 320, 320]               0
 AdaptiveAvgPool2d-8             [-1, 32, 1, 1]               0
            Conv2d-9              [-1, 8, 1, 1]             264
             ReLU-10              [-1, 8, 1, 1]               0
           Conv2d-11             [-1, 32, 1, 1]             288
      Hardsigmoid-12             [-1, 32, 1, 1]               0
         SEModule-13         [-1, 32, 320, 320]               0
           Conv2d-14         [-1, 32, 320, 320]           1,024
      BatchNorm2d-15         [-1, 32, 320, 320]              64
        Hardswish-16         [-1, 32, 320, 320]               0
      ConvBNLayer-17         [-1, 32, 320, 320]               0
DepthwiseSeparable-18         [-1, 32, 320, 320]               0
           Conv2d-19         [-1, 32, 160, 160]             288
      BatchNorm2d-20         [-1, 32, 160, 160]              64
        Hardswish-21         [-1, 32, 160, 160]               0
      ConvBNLayer-22         [-1, 32, 160, 160]               0
AdaptiveAvgPool2d-23             [-1, 32, 1, 1]               0
           Conv2d-24              [-1, 8, 1, 1]             264
             ReLU-25              [-1, 8, 1, 1]               0
           Conv2d-26             [-1, 32, 1, 1]             288
      Hardsigmoid-27             [-1, 32, 1, 1]               0
         SEModule-28         [-1, 32, 160, 160]               0
           Conv2d-29         [-1, 64, 160, 160]           2,048
      BatchNorm2d-30         [-1, 64, 160, 160]             128
        Hardswish-31         [-1, 64, 160, 160]               0
      ConvBNLayer-32         [-1, 64, 160, 160]               0
DepthwiseSeparable-33         [-1, 64, 160, 160]               0
           Conv2d-34         [-1, 64, 160, 160]             576
      BatchNorm2d-35         [-1, 64, 160, 160]             128
        Hardswish-36         [-1, 64, 160, 160]               0
      ConvBNLayer-37         [-1, 64, 160, 160]               0
AdaptiveAvgPool2d-38             [-1, 64, 1, 1]               0
           Conv2d-39             [-1, 16, 1, 1]           1,040
             ReLU-40             [-1, 16, 1, 1]               0
           Conv2d-41             [-1, 64, 1, 1]           1,088
      Hardsigmoid-42             [-1, 64, 1, 1]               0
         SEModule-43         [-1, 64, 160, 160]               0
           Conv2d-44         [-1, 64, 160, 160]           4,096
      BatchNorm2d-45         [-1, 64, 160, 160]             128
        Hardswish-46         [-1, 64, 160, 160]               0
      ConvBNLayer-47         [-1, 64, 160, 160]               0
DepthwiseSeparable-48         [-1, 64, 160, 160]               0
           Conv2d-49           [-1, 64, 80, 80]             576
      BatchNorm2d-50           [-1, 64, 80, 80]             128
        Hardswish-51           [-1, 64, 80, 80]               0
      ConvBNLayer-52           [-1, 64, 80, 80]               0
AdaptiveAvgPool2d-53             [-1, 64, 1, 1]               0
           Conv2d-54             [-1, 16, 1, 1]           1,040
             ReLU-55             [-1, 16, 1, 1]               0
           Conv2d-56             [-1, 64, 1, 1]           1,088
      Hardsigmoid-57             [-1, 64, 1, 1]               0
         SEModule-58           [-1, 64, 80, 80]               0
           Conv2d-59          [-1, 128, 80, 80]           8,192
      BatchNorm2d-60          [-1, 128, 80, 80]             256
        Hardswish-61          [-1, 128, 80, 80]               0
      ConvBNLayer-62          [-1, 128, 80, 80]               0
DepthwiseSeparable-63          [-1, 128, 80, 80]               0
           Conv2d-64          [-1, 128, 80, 80]           1,152
      BatchNorm2d-65          [-1, 128, 80, 80]             256
        Hardswish-66          [-1, 128, 80, 80]               0
      ConvBNLayer-67          [-1, 128, 80, 80]               0
AdaptiveAvgPool2d-68            [-1, 128, 1, 1]               0
           Conv2d-69             [-1, 32, 1, 1]           4,128
             ReLU-70             [-1, 32, 1, 1]               0
           Conv2d-71            [-1, 128, 1, 1]           4,224
      Hardsigmoid-72            [-1, 128, 1, 1]               0
         SEModule-73          [-1, 128, 80, 80]               0
           Conv2d-74          [-1, 128, 80, 80]          16,384
      BatchNorm2d-75          [-1, 128, 80, 80]             256
        Hardswish-76          [-1, 128, 80, 80]               0
      ConvBNLayer-77          [-1, 128, 80, 80]               0
DepthwiseSeparable-78          [-1, 128, 80, 80]               0
           Conv2d-79          [-1, 128, 40, 40]           1,152
      BatchNorm2d-80          [-1, 128, 40, 40]             256
        Hardswish-81          [-1, 128, 40, 40]               0
      ConvBNLayer-82          [-1, 128, 40, 40]               0
AdaptiveAvgPool2d-83            [-1, 128, 1, 1]               0
           Conv2d-84             [-1, 32, 1, 1]           4,128
             ReLU-85             [-1, 32, 1, 1]               0
           Conv2d-86            [-1, 128, 1, 1]           4,224
      Hardsigmoid-87            [-1, 128, 1, 1]               0
         SEModule-88          [-1, 128, 40, 40]               0
           Conv2d-89          [-1, 256, 40, 40]          32,768
      BatchNorm2d-90          [-1, 256, 40, 40]             512
        Hardswish-91          [-1, 256, 40, 40]               0
      ConvBNLayer-92          [-1, 256, 40, 40]               0
DepthwiseSeparable-93          [-1, 256, 40, 40]               0
           Conv2d-94          [-1, 256, 40, 40]           6,400
      BatchNorm2d-95          [-1, 256, 40, 40]             512
        Hardswish-96          [-1, 256, 40, 40]               0
      ConvBNLayer-97          [-1, 256, 40, 40]               0
AdaptiveAvgPool2d-98            [-1, 256, 1, 1]               0
           Conv2d-99             [-1, 64, 1, 1]          16,448
            ReLU-100             [-1, 64, 1, 1]               0
          Conv2d-101            [-1, 256, 1, 1]          16,640
     Hardsigmoid-102            [-1, 256, 1, 1]               0
        SEModule-103          [-1, 256, 40, 40]               0
          Conv2d-104          [-1, 256, 40, 40]          65,536
     BatchNorm2d-105          [-1, 256, 40, 40]             512
       Hardswish-106          [-1, 256, 40, 40]               0
     ConvBNLayer-107          [-1, 256, 40, 40]               0
DepthwiseSeparable-108          [-1, 256, 40, 40]               0
          Conv2d-109          [-1, 256, 40, 40]           6,400
     BatchNorm2d-110          [-1, 256, 40, 40]             512
       Hardswish-111          [-1, 256, 40, 40]               0
     ConvBNLayer-112          [-1, 256, 40, 40]               0
AdaptiveAvgPool2d-113            [-1, 256, 1, 1]               0
          Conv2d-114             [-1, 64, 1, 1]          16,448
            ReLU-115             [-1, 64, 1, 1]               0
          Conv2d-116            [-1, 256, 1, 1]          16,640
     Hardsigmoid-117            [-1, 256, 1, 1]               0
        SEModule-118          [-1, 256, 40, 40]               0
          Conv2d-119          [-1, 256, 40, 40]          65,536
     BatchNorm2d-120          [-1, 256, 40, 40]             512
       Hardswish-121          [-1, 256, 40, 40]               0
     ConvBNLayer-122          [-1, 256, 40, 40]               0
DepthwiseSeparable-123          [-1, 256, 40, 40]               0
          Conv2d-124          [-1, 256, 40, 40]           6,400
     BatchNorm2d-125          [-1, 256, 40, 40]             512
       Hardswish-126          [-1, 256, 40, 40]               0
     ConvBNLayer-127          [-1, 256, 40, 40]               0
AdaptiveAvgPool2d-128            [-1, 256, 1, 1]               0
          Conv2d-129             [-1, 64, 1, 1]          16,448
            ReLU-130             [-1, 64, 1, 1]               0
          Conv2d-131            [-1, 256, 1, 1]          16,640
     Hardsigmoid-132            [-1, 256, 1, 1]               0
        SEModule-133          [-1, 256, 40, 40]               0
          Conv2d-134          [-1, 256, 40, 40]          65,536
     BatchNorm2d-135          [-1, 256, 40, 40]             512
       Hardswish-136          [-1, 256, 40, 40]               0
     ConvBNLayer-137          [-1, 256, 40, 40]               0
DepthwiseSeparable-138          [-1, 256, 40, 40]               0
          Conv2d-139          [-1, 256, 40, 40]           6,400
     BatchNorm2d-140          [-1, 256, 40, 40]             512
       Hardswish-141          [-1, 256, 40, 40]               0
     ConvBNLayer-142          [-1, 256, 40, 40]               0
AdaptiveAvgPool2d-143            [-1, 256, 1, 1]               0
          Conv2d-144             [-1, 64, 1, 1]          16,448
            ReLU-145             [-1, 64, 1, 1]               0
          Conv2d-146            [-1, 256, 1, 1]          16,640
     Hardsigmoid-147            [-1, 256, 1, 1]               0
        SEModule-148          [-1, 256, 40, 40]               0
          Conv2d-149          [-1, 256, 40, 40]          65,536
     BatchNorm2d-150          [-1, 256, 40, 40]             512
       Hardswish-151          [-1, 256, 40, 40]               0
     ConvBNLayer-152          [-1, 256, 40, 40]               0
DepthwiseSeparable-153          [-1, 256, 40, 40]               0
          Conv2d-154          [-1, 256, 40, 40]           6,400
     BatchNorm2d-155          [-1, 256, 40, 40]             512
       Hardswish-156          [-1, 256, 40, 40]               0
     ConvBNLayer-157          [-1, 256, 40, 40]               0
AdaptiveAvgPool2d-158            [-1, 256, 1, 1]               0
          Conv2d-159             [-1, 64, 1, 1]          16,448
            ReLU-160             [-1, 64, 1, 1]               0
          Conv2d-161            [-1, 256, 1, 1]          16,640
     Hardsigmoid-162            [-1, 256, 1, 1]               0
        SEModule-163          [-1, 256, 40, 40]               0
          Conv2d-164          [-1, 256, 40, 40]          65,536
     BatchNorm2d-165          [-1, 256, 40, 40]             512
       Hardswish-166          [-1, 256, 40, 40]               0
     ConvBNLayer-167          [-1, 256, 40, 40]               0
DepthwiseSeparable-168          [-1, 256, 40, 40]               0
          Conv2d-169           [-1, 64, 40, 40]          32,768
     BatchNorm2d-170           [-1, 64, 40, 40]             128
     ConvBNLayer-171           [-1, 64, 40, 40]               0
          Conv2d-172           [-1, 64, 40, 40]          32,768
     BatchNorm2d-173           [-1, 64, 40, 40]             128
     ConvBNLayer-174           [-1, 64, 40, 40]               0
          Conv2d-175           [-1, 64, 40, 40]           4,096
     BatchNorm2d-176           [-1, 64, 40, 40]             128
     ConvBNLayer-177           [-1, 64, 40, 40]               0
          Conv2d-178           [-1, 64, 40, 40]          36,864
     BatchNorm2d-179           [-1, 64, 40, 40]             128
     ConvBNLayer-180           [-1, 64, 40, 40]               0
DarknetBottleneck-181           [-1, 64, 40, 40]               0
          Conv2d-182           [-1, 64, 40, 40]           4,096
     BatchNorm2d-183           [-1, 64, 40, 40]             128
     ConvBNLayer-184           [-1, 64, 40, 40]               0
          Conv2d-185           [-1, 64, 40, 40]          36,864
     BatchNorm2d-186           [-1, 64, 40, 40]             128
     ConvBNLayer-187           [-1, 64, 40, 40]               0
DarknetBottleneck-188           [-1, 64, 40, 40]               0
          Conv2d-189          [-1, 128, 40, 40]          16,384
     BatchNorm2d-190          [-1, 128, 40, 40]             256
     ConvBNLayer-191          [-1, 128, 40, 40]               0
        CSPLayer-192          [-1, 128, 40, 40]               0
        Upsample-193          [-1, 128, 80, 80]               0
              up-194          [-1, 128, 80, 80]               0
          Conv2d-195           [-1, 32, 80, 80]           8,192
     BatchNorm2d-196           [-1, 32, 80, 80]              64
     ConvBNLayer-197           [-1, 32, 80, 80]               0
          Conv2d-198           [-1, 32, 80, 80]           8,192
     BatchNorm2d-199           [-1, 32, 80, 80]              64
     ConvBNLayer-200           [-1, 32, 80, 80]               0
          Conv2d-201           [-1, 32, 80, 80]           1,024
     BatchNorm2d-202           [-1, 32, 80, 80]              64
     ConvBNLayer-203           [-1, 32, 80, 80]               0
          Conv2d-204           [-1, 32, 80, 80]           9,216
     BatchNorm2d-205           [-1, 32, 80, 80]              64
     ConvBNLayer-206           [-1, 32, 80, 80]               0
DarknetBottleneck-207           [-1, 32, 80, 80]               0
          Conv2d-208           [-1, 32, 80, 80]           1,024
     BatchNorm2d-209           [-1, 32, 80, 80]              64
     ConvBNLayer-210           [-1, 32, 80, 80]               0
          Conv2d-211           [-1, 32, 80, 80]           9,216
     BatchNorm2d-212           [-1, 32, 80, 80]              64
     ConvBNLayer-213           [-1, 32, 80, 80]               0
DarknetBottleneck-214           [-1, 32, 80, 80]               0
          Conv2d-215           [-1, 64, 80, 80]           4,096
     BatchNorm2d-216           [-1, 64, 80, 80]             128
     ConvBNLayer-217           [-1, 64, 80, 80]               0
        CSPLayer-218           [-1, 64, 80, 80]               0
        Upsample-219         [-1, 64, 160, 160]               0
              up-220         [-1, 64, 160, 160]               0
          Conv2d-221         [-1, 16, 160, 160]           2,048
     BatchNorm2d-222         [-1, 16, 160, 160]              32
     ConvBNLayer-223         [-1, 16, 160, 160]               0
          Conv2d-224         [-1, 16, 160, 160]           2,048
     BatchNorm2d-225         [-1, 16, 160, 160]              32
     ConvBNLayer-226         [-1, 16, 160, 160]               0
          Conv2d-227         [-1, 16, 160, 160]             256
     BatchNorm2d-228         [-1, 16, 160, 160]              32
     ConvBNLayer-229         [-1, 16, 160, 160]               0
          Conv2d-230         [-1, 16, 160, 160]           2,304
     BatchNorm2d-231         [-1, 16, 160, 160]              32
     ConvBNLayer-232         [-1, 16, 160, 160]               0
DarknetBottleneck-233         [-1, 16, 160, 160]               0
          Conv2d-234         [-1, 16, 160, 160]             256
     BatchNorm2d-235         [-1, 16, 160, 160]              32
     ConvBNLayer-236         [-1, 16, 160, 160]               0
          Conv2d-237         [-1, 16, 160, 160]           2,304
     BatchNorm2d-238         [-1, 16, 160, 160]              32
     ConvBNLayer-239         [-1, 16, 160, 160]               0
DarknetBottleneck-240         [-1, 16, 160, 160]               0
          Conv2d-241         [-1, 32, 160, 160]           1,024
     BatchNorm2d-242         [-1, 32, 160, 160]              64
     ConvBNLayer-243         [-1, 32, 160, 160]               0
        CSPLayer-244         [-1, 32, 160, 160]               0
        Upsample-245         [-1, 32, 320, 320]               0
              up-246         [-1, 32, 320, 320]               0
         Dropout-247         [-1, 32, 320, 320]               0
          Conv2d-248          [-1, 1, 320, 320]              33
         Dropout-249         [-1, 32, 320, 320]               0
          Conv2d-250          [-1, 1, 320, 320]              33
         Dropout-251         [-1, 32, 320, 320]               0
          Conv2d-252          [-1, 1, 320, 320]              33
         Dropout-253         [-1, 32, 320, 320]               0
          Conv2d-254          [-1, 1, 320, 320]              33
================================================================
Total params: 840,404
Trainable params: 840,404
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.39
Forward/backward pass size (MB): 1176.61
Params size (MB): 3.21
Estimated Total Size (MB): 1180.21
----------------------------------------------------------------
